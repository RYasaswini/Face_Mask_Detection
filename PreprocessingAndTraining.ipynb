{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Training the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\theje\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\theje\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Activation, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "########################################\n",
    "\n",
    "path='images'\n",
    "images=[]\n",
    "classNo=[]\n",
    "testRatio=0.2\n",
    "valRatio=0.2\n",
    "imgDimension=(32,32,3)\n",
    "\n",
    "#########################################\n",
    "\n",
    "myList=os.listdir(path)\n",
    "\n",
    "numOfClasses=len(myList)\n",
    "\n",
    "print(numOfClasses)\n",
    "\n",
    "# print(\"Importing Classes..........\")\n",
    "# for x in range(0, numOfClasses):\n",
    "# \tmyPicList=os.listdir(path+\"/\"+str(x))\n",
    "# \t# myData/0/img.jpg\n",
    "# \tfor y in myPicList:\n",
    "# \t\tcurImg=cv2.imread(path+\"/\"+str(x)+\"/\"+y)\n",
    "# \t\tcurImg=cv2.resize(curImg,(imgDimension[0],imgDimension[1]))\n",
    "# \t\timages.append(curImg)\n",
    "# \t\tclassNo.append(x)\n",
    "# \tprint(x)\n",
    "\n",
    "# images=np.array(images)\n",
    "# classNo=np.array(classNo)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #########Spliting The Data###########\n",
    "\n",
    "# x_train, x_test, y_train, y_test=train_test_split(images, classNo, test_size=testRatio)\n",
    "# x_train, x_validation, y_train, y_validation=train_test_split(x_train, y_train, test_size=valRatio)\n",
    "\n",
    "\n",
    "# # # print(x_train.shape)\n",
    "\n",
    "# numOfSample=[]\n",
    "\n",
    "# for x in range(0,numOfClasses):\n",
    "# \tnumOfSample.append(len(np.where(y_train==x)[0]))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,5))\n",
    "# plt.bar(range(0, numOfClasses),numOfSample)\n",
    "# plt.title(\"Bar Plot of Classes & Images\")\n",
    "# plt.xlabel(\"No Of Classes\")\n",
    "# plt.ylabel(\"No of Images\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# def preprocessing(img):\n",
    "# \t# img=np.astype(\"uint8\")\n",
    "# \timg=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# \timg=cv2.equalizeHist(img)\n",
    "# \timg=img/255\n",
    "# \treturn img\n",
    "\n",
    "\n",
    "# x_train=np.array(list(map(preprocessing, x_train)))\n",
    "# x_test=np.array(list(map(preprocessing, x_test)))\n",
    "# x_validation=np.array(list(map(preprocessing, x_validation)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x_train=x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],1)\n",
    "# x_test=x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2],1)\n",
    "# x_validation=x_validation.reshape(x_validation.shape[0], x_validation.shape[1], x_validation.shape[2],1)\n",
    "\n",
    "\n",
    "# dataGen=ImageDataGenerator(\n",
    "# \twidth_shift_range=0.1,\n",
    "# \theight_shift_range=0.1,\n",
    "# \tzoom_range=0.2,\n",
    "# \tshear_range=0.1,\n",
    "# \trotation_range=10)\n",
    "\n",
    "# dataGen.fit(x_train)\n",
    "\n",
    "# y_train=to_categorical(y_train, numOfClasses)\n",
    "# y_test=to_categorical(y_test, numOfClasses)\n",
    "# y_validation=to_categorical(y_validation, numOfClasses)\n",
    "\n",
    "\n",
    "# def myModel():\n",
    "# \tsizeOfFilter1=(3,3)\n",
    "# \tsizeOfFilter2=(3,3)\n",
    "# \tsizeOfPool=(2,2)\n",
    "\n",
    "# \tmodel=Sequential()\n",
    "# \tmodel.add((Conv2D(32, sizeOfFilter1, input_shape=(imgDimension[0],imgDimension[1],1),activation='relu')))\n",
    "# \tmodel.add((Conv2D(32, sizeOfFilter1,activation='relu')))\n",
    "# \tmodel.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "\n",
    "# \tmodel.add((Conv2D(64, sizeOfFilter2,activation='relu')))\n",
    "# \tmodel.add((Conv2D(64, sizeOfFilter2,activation='relu')))\n",
    "# \tmodel.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "# \tmodel.add(Flatten())\n",
    "# \tmodel.add(Dense(64, activation='relu'))\n",
    "# \tmodel.add(Dropout(0.5))\n",
    "# \tmodel.add(Dense(numOfClasses, activation='softmax'))\n",
    "# \tmodel.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# \treturn model\n",
    "\n",
    "# model=myModel()\n",
    "# print(model.summary())\n",
    "\n",
    "# history=model.fit_generator(dataGen.flow(x_train, y_train,batch_size=50),\n",
    "# \tsteps_per_epoch=1000,\n",
    "# \tepochs=2,\n",
    "# \tvalidation_data=(x_validation,y_validation),\n",
    "# \tshuffle=1)\n",
    "\n",
    "# model.save(\"MyTrainingModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.18.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: C:\\Users\\theje\\AppData\\Roaming\\Python\\Python312\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\theje\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\theje\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImageDataGenerator' from 'keras.preprocessing.image' (C:\\Users\\theje\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\api\\preprocessing\\image\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Path to the dataset\n",
    "path = 'images'\n",
    "images = []\n",
    "classNo = []\n",
    "imgDimension = (32, 32, 3)  # Desired image dimensions\n",
    "\n",
    "# List of all class directories in the 'images' folder\n",
    "myList = os.listdir(path)\n",
    "\n",
    "# Determine number of classes (subdirectories in 'images')\n",
    "numOfClasses = len(myList)\n",
    "\n",
    "print(f\"Number of classes: {numOfClasses}\")\n",
    "\n",
    "# Loop through each class folder\n",
    "for x in range(0, numOfClasses):\n",
    "    class_path = os.path.join(path, str(x))  # Build the class directory path\n",
    "\n",
    "    # Check if the class folder exists\n",
    "    if os.path.exists(class_path):\n",
    "        myPicList = os.listdir(class_path)  # List images in the class folder\n",
    "\n",
    "        # Loop through each image file in the class folder\n",
    "        for y in myPicList:\n",
    "            image_path = os.path.join(class_path, y)  # Build the image file path\n",
    "\n",
    "            # Read and resize the image\n",
    "            curImg = cv2.imread(image_path)\n",
    "            if curImg is not None:\n",
    "                curImg = cv2.resize(curImg, (imgDimension[0], imgDimension[1]))  # Resize image\n",
    "                images.append(curImg)\n",
    "                classNo.append(x)\n",
    "            else:\n",
    "                print(f\"Warning: Could not read image {image_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Directory for class {x} not found.\")\n",
    "\n",
    "# Convert lists to numpy arrays for further processing\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "\n",
    "print(f\"Total images: {len(images)}\")\n",
    "\n",
    "# ######### Splitting the Data ###########\n",
    "testRatio = 0.2\n",
    "valRatio = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=valRatio)\n",
    "\n",
    "# Create bar plot for the number of samples in each class\n",
    "numOfSample = []\n",
    "\n",
    "for x in range(0, numOfClasses):\n",
    "    numOfSample.append(len(np.where(y_train == x)[0]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, numOfClasses), numOfSample)\n",
    "plt.title(\"Bar Plot of Classes & Images\")\n",
    "plt.xlabel(\"No Of Classes\")\n",
    "plt.ylabel(\"No of Images\")\n",
    "plt.show()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    img = cv2.equalizeHist(img)  # Equalize the histogram\n",
    "    img = img / 255  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "# Apply preprocessing\n",
    "x_train = np.array(list(map(preprocessing, x_train)))\n",
    "x_test = np.array(list(map(preprocessing, x_test)))\n",
    "x_validation = np.array(list(map(preprocessing, x_validation)))\n",
    "\n",
    "# Reshape to match the expected input for Conv2D (adding the channel dimension)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0], x_validation.shape[1], x_validation.shape[2], 1)\n",
    "\n",
    "# Data augmentation using ImageDataGenerator\n",
    "dataGen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=10\n",
    ")\n",
    "\n",
    "dataGen.fit(x_train)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train, numOfClasses)\n",
    "y_test = to_categorical(y_test, numOfClasses)\n",
    "y_validation = to_categorical(y_validation, numOfClasses)\n",
    "\n",
    "# Build the CNN model\n",
    "def myModel():\n",
    "    sizeOfFilter1 = (3, 3)\n",
    "    sizeOfFilter2 = (3, 3)\n",
    "    sizeOfPool = (2, 2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, sizeOfFilter1, input_shape=(imgDimension[0], imgDimension[1], 1), activation='relu'))\n",
    "    model.add(Conv2D(32, sizeOfFilter1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    \n",
    "    model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and summarize the model\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model using fit instead of fit_generator\n",
    "history = model.fit(\n",
    "    dataGen.flow(x_train, y_train, batch_size=50),\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=2,\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"MyTrainingModel.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Path to the dataset\n",
    "path = 'images'\n",
    "images = []\n",
    "classNo = []\n",
    "imgDimension = (32, 32, 3)  # Desired image dimensions\n",
    "\n",
    "# List of all class directories in the 'images' folder\n",
    "myList = os.listdir(path)\n",
    "\n",
    "# Determine number of classes (subdirectories in 'images')\n",
    "numOfClasses = len(myList)\n",
    "\n",
    "print(f\"Number of classes: {numOfClasses}\")\n",
    "\n",
    "# Loop through each class folder\n",
    "for x in range(0, numOfClasses):\n",
    "    class_path = os.path.join(path, str(x))  # Build the class directory path\n",
    "\n",
    "    # Check if the class folder exists\n",
    "    if os.path.exists(class_path):\n",
    "        myPicList = os.listdir(class_path)  # List images in the class folder\n",
    "\n",
    "        # Loop through each image file in the class folder\n",
    "        for y in myPicList:\n",
    "            image_path = os.path.join(class_path, y)  # Build the image file path\n",
    "\n",
    "            # Read and resize the image\n",
    "            curImg = cv2.imread(image_path)\n",
    "            if curImg is not None:\n",
    "                curImg = cv2.resize(curImg, (imgDimension[0], imgDimension[1]))  # Resize image\n",
    "                images.append(curImg)\n",
    "                classNo.append(x)\n",
    "            else:\n",
    "                print(f\"Warning: Could not read image {image_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Directory for class {x} not found.\")\n",
    "\n",
    "# Convert lists to numpy arrays for further processing\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "\n",
    "print(f\"Total images: {len(images)}\")\n",
    "\n",
    "# ######### Splitting the Data ###########\n",
    "testRatio = 0.2\n",
    "valRatio = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=valRatio)\n",
    "\n",
    "# Create bar plot for the number of samples in each class\n",
    "numOfSample = []\n",
    "\n",
    "for x in range(0, numOfClasses):\n",
    "    numOfSample.append(len(np.where(y_train == x)[0]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, numOfClasses), numOfSample)\n",
    "plt.title(\"Bar Plot of Classes & Images\")\n",
    "plt.xlabel(\"No Of Classes\")\n",
    "plt.ylabel(\"No of Images\")\n",
    "plt.show()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    img = cv2.equalizeHist(img)  # Equalize the histogram\n",
    "    img = img / 255  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "# Apply preprocessing\n",
    "x_train = np.array(list(map(preprocessing, x_train)))\n",
    "x_test = np.array(list(map(preprocessing, x_test)))\n",
    "x_validation = np.array(list(map(preprocessing, x_validation)))\n",
    "\n",
    "# Reshape to match the expected input for Conv2D (adding the channel dimension)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0], x_validation.shape[1], x_validation.shape[2], 1)\n",
    "\n",
    "# Data augmentation using ImageDataGenerator\n",
    "dataGen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=10\n",
    ")\n",
    "\n",
    "dataGen.fit(x_train)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train, numOfClasses)\n",
    "y_test = to_categorical(y_test, numOfClasses)\n",
    "y_validation = to_categorical(y_validation, numOfClasses)\n",
    "\n",
    "# Build the CNN model\n",
    "def myModel():\n",
    "    sizeOfFilter1 = (3, 3)\n",
    "    sizeOfFilter2 = (3, 3)\n",
    "    sizeOfPool = (2, 2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, sizeOfFilter1, input_shape=(imgDimension[0], imgDimension[1], 1), activation='relu'))\n",
    "    model.add(Conv2D(32, sizeOfFilter1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    \n",
    "    model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and summarize the model\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model using fit instead of fit_generator\n",
    "history = model.fit(\n",
    "    dataGen.flow(x_train, y_train, batch_size=50),\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=2,\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"MyTrainingModel.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 1\n",
      "Warning: Directory for class 0 not found.\n",
      "Total images: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m testRatio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m     57\u001b[0m valRatio \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[1;32m---> 59\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassNo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m x_train, x_validation, y_train, y_validation \u001b[38;5;241m=\u001b[39m train_test_split(x_train, y_train, test_size\u001b[38;5;241m=\u001b[39mvalRatio)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Create bar plot for the number of samples in each class\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2785\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2782\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2784\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2785\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2787\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_split.py:2415\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2412\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2416\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2417\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2419\u001b[0m     )\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Path to the dataset\n",
    "path = 'images'\n",
    "images = []\n",
    "classNo = []\n",
    "imgDimension = (32, 32, 3)  # Desired image dimensions\n",
    "\n",
    "# List of all class directories in the 'images' folder\n",
    "myList = os.listdir(path)\n",
    "\n",
    "# Determine number of classes (subdirectories in 'images')\n",
    "numOfClasses = len(myList)\n",
    "\n",
    "print(f\"Number of classes: {numOfClasses}\")\n",
    "\n",
    "# Loop through each class folder\n",
    "for x in range(0, numOfClasses):\n",
    "    class_path = os.path.join(path, str(x))  # Build the class directory path\n",
    "\n",
    "    # Check if the class folder exists\n",
    "    if os.path.exists(class_path):\n",
    "        myPicList = os.listdir(class_path)  # List images in the class folder\n",
    "\n",
    "        # Loop through each image file in the class folder\n",
    "        for y in myPicList:\n",
    "            image_path = os.path.join(class_path, y)  # Build the image file path\n",
    "\n",
    "            # Read and resize the image\n",
    "            curImg = cv2.imread(image_path)\n",
    "            if curImg is not None:\n",
    "                curImg = cv2.resize(curImg, (imgDimension[0], imgDimension[1]))  # Resize image\n",
    "                images.append(curImg)\n",
    "                classNo.append(x)\n",
    "            else:\n",
    "                print(f\"Warning: Could not read image {image_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: Directory for class {x} not found.\")\n",
    "\n",
    "# Convert lists to numpy arrays for further processing\n",
    "images = np.array(images)\n",
    "classNo = np.array(classNo)\n",
    "\n",
    "print(f\"Total images: {len(images)}\")\n",
    "\n",
    "# ######### Splitting the Data ###########\n",
    "testRatio = 0.2\n",
    "valRatio = 0.2\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=valRatio)\n",
    "\n",
    "# Create bar plot for the number of samples in each class\n",
    "numOfSample = []\n",
    "\n",
    "for x in range(0, numOfClasses):\n",
    "    numOfSample.append(len(np.where(y_train == x)[0]))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(0, numOfClasses), numOfSample)\n",
    "plt.title(\"Bar Plot of Classes & Images\")\n",
    "plt.xlabel(\"No Of Classes\")\n",
    "plt.ylabel(\"No of Images\")\n",
    "plt.show()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocessing(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    img = cv2.equalizeHist(img)  # Equalize the histogram\n",
    "    img = img / 255  # Normalize to [0, 1]\n",
    "    return img\n",
    "\n",
    "# Apply preprocessing\n",
    "x_train = np.array(list(map(preprocessing, x_train)))\n",
    "x_test = np.array(list(map(preprocessing, x_test)))\n",
    "x_validation = np.array(list(map(preprocessing, x_validation)))\n",
    "\n",
    "# Reshape to match the expected input for Conv2D (adding the channel dimension)\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "x_validation = x_validation.reshape(x_validation.shape[0], x_validation.shape[1], x_validation.shape[2], 1)\n",
    "\n",
    "# Data augmentation using ImageDataGenerator\n",
    "dataGen = ImageDataGenerator(\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=10\n",
    ")\n",
    "\n",
    "dataGen.fit(x_train)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = to_categorical(y_train, numOfClasses)\n",
    "y_test = to_categorical(y_test, numOfClasses)\n",
    "y_validation = to_categorical(y_validation, numOfClasses)\n",
    "\n",
    "# Build the CNN model\n",
    "def myModel():\n",
    "    sizeOfFilter1 = (3, 3)\n",
    "    sizeOfFilter2 = (3, 3)\n",
    "    sizeOfPool = (2, 2)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, sizeOfFilter1, input_shape=(imgDimension[0], imgDimension[1], 1), activation='relu'))\n",
    "    model.add(Conv2D(32, sizeOfFilter1, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(Conv2D(64, sizeOfFilter2, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=sizeOfPool))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(numOfClasses, activation='softmax'))\n",
    "    \n",
    "    model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize and summarize the model\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model using fit instead of fit_generator\n",
    "history = model.fit(\n",
    "    dataGen.flow(x_train, y_train, batch_size=50),\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=2,\n",
    "    validation_data=(x_validation, y_validation),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"MyTrainingModel.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
